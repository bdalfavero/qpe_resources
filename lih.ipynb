{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e38da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from itertools import accumulate\n",
    "from time import perf_counter_ns\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix, kron, identity\n",
    "import cirq\n",
    "import openfermion as of\n",
    "from openfermionpyscf import run_pyscf\n",
    "import quimb.tensor as qtn\n",
    "from quimb.tensor.tensor_1d import MatrixProductState, MatrixProductOperator\n",
    "from convert import to_groups_of\n",
    "from error_pert import get_v2_sarray\n",
    "from qpe_trotter import v2_pauli_sum, v2_qubop\n",
    "from kcommute import get_si_sets\n",
    "from tensor_network_common import pauli_sum_to_mpo, mps_to_vector\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0010118-2ddc-404c-a1b9-75e066009eca",
   "metadata": {},
   "source": [
    "This notebook requires quantum-toolbox installed: https://github.com/jdrowland/quantum-toolbox/\n",
    "\n",
    "The following timing and validation results are run on 10 amd20 nodes with 16 GB of memory.  Comparison is made to cirq.PauliSum only.  Timing results are significantly worse on this hardware than the original notebook timing results.  This likely owes to superior memory streaming on the original (Mac Pro?) hardware.  Speedups achieved are plausibly robust provided computations remain memory-bound.  From other work I have done, AMD24 hardware remains the best option on ICER for memory bound compute, and should be constrained for cluster work of this nature.  Parallelization is implemented to demonstrate that the remaining dominant component of the computation is in the large number of expectation values which are embarassingly parallel.  Highly recommend parallelizing this differently than demonstrated in this notebook in practice by utilizing the cluster's scavenger queue to produce a very large number of cores as you scale beyond LiH.  Such an approach is approach is not friendly to the notebook format however, and as such we utilize multiprocessing.\n",
    "\n",
    "The quantum-toolbox contains a relatively diverse set of modular functions built upon symplectic data structures primarily intended for grouping Pauli operators and computing their expectation values.  Signficant performance detriments result from changing between formats and as such it is recommended to work exclusively with the symplectic form as much as possible.  Ideally all conversion happen directly to and from symplectic form without intermediate products.  This effect shouldn't inherently improve scaling, but it is likely for memory bound processes such as commutativity checks, the cirq objects induce non-linear overhead.  \n",
    "\n",
    "The toolbox contains methods for converting between and computing with different formats such as cirq, qiskit, and tensor networks.\n",
    "\n",
    "To highlight a couple of speedups:  Grouping occurs in a mere 15 ms as compared to the original 5.9s, a 393x speedup.  This speedup grows as problems become more challenging.  Serial computation of expectation values exhibits a 2.26x speedup, while the parallel version is an additional 6.5x on the expectation value computation, not quite achieving the theoretical 10x, for a relative speedup (including build time) of 4.2x.  No comparison is made to the original because for a fair comparison one would also need to parallelize the original cirq based code as well.  \n",
    "\n",
    "In general, with enough cores this computation can be driven toward the build time + grouping time.  Parallelization of the symplectic build_v2_terms is also possible should this become a bottleneck, though a little bit trickier to do.  A reasonable approach might be to produce the O(N^2) list of commutators [A,B], and then proceed to parallelize the last computation.  Combining the results of the different computations results in some overhead, as an 'abstract' sum of strings need to be combined, rather than scalars.  This can be avoided by parallelizing the expectation values at the level of the commutator also.\n",
    "\n",
    "The embarassingly parallel aspect of the expectation values still remains a non-trivial problem as you scale to a problem of the size of OWP.  The number of expectation values scales very poorly with the number of terms, something like O(M^3) where M is the number of terms, so scaling to OWP is at worst a trillion times worse.  Even with scavenger queue, the number of cores you could access in parallel are roughly 10^4, so this remains prohibitive.  Perhaps computing all of the commutators is possible, but computing their expectation values *exactly* for a general state seems unlikely.  For grouping, the number of expectation values scales linearly with M, so this remains feasible to do.  Perhaps you could still do this exactly for a relatively unentangled state, such as HF, or by somehow truncating the number of expectation values required, though this seems unlikely to meet your goals.  \n",
    "\n",
    "\n",
    "At the LiH problem size, I think you will be always worse off doing it this way rather than sparse matrix methods, but as problem size grows, I expect the sparse methods to eventually be worse, perhaps comparable for water with maximal parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d3aad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF energy: -7.767362135748557\n",
      "FCI energy: -7.784460280031223\n",
      "Hamiltonian has 12 qubits and 631 terms.\n"
     ]
    }
   ],
   "source": [
    "molec = \"LiH\"\n",
    "basis = \"sto-3g\"\n",
    "n_elec = 4\n",
    "geometry = of.chem.geometry_from_pubchem(molec)\n",
    "multiplicity = 1\n",
    "molecule = of.chem.MolecularData(\n",
    "    geometry, basis, multiplicity\n",
    ")\n",
    "molecule = run_pyscf(molecule, run_scf=1, run_fci=1)\n",
    "print(f\"HF energy:\", molecule.hf_energy)\n",
    "print(f\"FCI energy:\", molecule.fci_energy)\n",
    "hamiltonian = molecule.get_molecular_hamiltonian()\n",
    "hamiltonian_qubop = of.transforms.jordan_wigner(hamiltonian)\n",
    "hamiltonian_psum = of.transforms.qubit_operator_to_pauli_sum(hamiltonian_qubop)\n",
    "\n",
    "nq = of.utils.count_qubits(hamiltonian_qubop)\n",
    "nterms = len(hamiltonian_qubop.terms)\n",
    "print(f\"Hamiltonian has {nq} qubits and {nterms} terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740593cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_inds = ['k0', 'k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k7', 'k8', 'k9', 'k10', 'k11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/cotengra/hyperoptimizers/hyper.py:55: UserWarning: Couldn't find `optuna`, `cmaes`, or `nevergrad` so will use completely random sampling in place of hyper-optimization. It is recommended to install one of these libraries for higher quality contraction paths.\n",
      "  warnings.warn(\n",
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return func(*args, **kwargs)\n",
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: overflow encountered in matmul\n",
      "  return func(*args, **kwargs)\n",
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: invalid value encountered in matmul\n",
      "  return func(*args, **kwargs)\n",
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return func(*args, **kwargs)\n",
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: overflow encountered in matmul\n",
      "  return func(*args, **kwargs)\n",
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: invalid value encountered in matmul\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "qs = cirq.LineQubit.range(nq)\n",
    "hamiltonian_mpo = pauli_sum_to_mpo(hamiltonian_psum, qs, 100)\n",
    "dmrg = qtn.DMRG(hamiltonian_mpo, bond_dims=15)\n",
    "converged = dmrg.solve()\n",
    "if not converged:\n",
    "    print(\"DMRG did not converge.\")\n",
    "ground_state = dmrg.state\n",
    "ground_state_vec = mps_to_vector(ground_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ecbf313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42 groups.\n",
      "Elapsed time: 1.49811e+09 ns\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter_ns()\n",
    "groups = get_si_sets(hamiltonian_psum, nq)\n",
    "end_time = perf_counter_ns()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"There are {len(groups)} groups.\")\n",
    "print(f\"Elapsed time: {elapsed_time:4.5e} ns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7f159",
   "metadata": {},
   "source": [
    "## Sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147359f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got eps2=0.009768790655924071 in 1.32852e+09 ns\n"
     ]
    }
   ],
   "source": [
    "# Use the code from the paper.\n",
    "start_time = perf_counter_ns()\n",
    "group_qubops = to_groups_of(groups)\n",
    "sparse_frag_ops = []\n",
    "# Convert group operators to sparse matrices.\n",
    "# We must make sure the matrices have all the same size.\n",
    "# If a matrix is not big enough, tensor it with I on the right.\n",
    "for op in group_qubops:\n",
    "    nq_op = of.utils.count_qubits(op)\n",
    "    op_sparse = of.linalg.get_sparse_operator(op)\n",
    "    if nq_op != nq:\n",
    "        eye_diff = identity(2 ** (nq - nq_op), dtype=\"complex\", format='csc')\n",
    "        new_op = kron(op_sparse, eye_diff, format=\"csc\")\n",
    "        sparse_frag_ops.append(new_op)\n",
    "    else:\n",
    "        sparse_frag_ops.append(op_sparse)\n",
    "v2_sparse = get_v2_sarray(sparse_frag_ops)\n",
    "eps2 = np.vdot(ground_state_vec, v2_sparse @ ground_state_vec).real\n",
    "end_time = perf_counter_ns()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Got eps2={eps2} in {elapsed_time:4.5e} ns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7531ff",
   "metadata": {},
   "source": [
    "## `cirq.PauliSum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2450fb15",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m start_time = perf_counter_ns()\n\u001b[32m      2\u001b[39m group_psums = [\u001b[38;5;28msum\u001b[39m(group) \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groups]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m v2_psum = \u001b[43mv2_pauli_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_psums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m qubit_map = {q: i \u001b[38;5;28;01mfor\u001b[39;00m i, q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(qs)}\n\u001b[32m      5\u001b[39m eps2_psum = v2_psum.expectation_from_state_vector(ground_state_vec, qubit_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phd/wellcome/qpe_resources/qpe_trotter.py:39\u001b[39m, in \u001b[36mv2_pauli_sum\u001b[39m\u001b[34m(hamiltonian_terms)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i,j,k \u001b[38;5;129;01min\u001b[39;00m term_combs_V1_v2:\n\u001b[32m     38\u001b[39m     V1_term = commutator(i, j)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     v2 += - \u001b[43mcommutator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV1_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m*\u001b[32m1\u001b[39m/\u001b[32m3\u001b[39m - commutator(V1_term, j)*\u001b[32m1\u001b[39m/\u001b[32m6\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m v2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/phd/wellcome/qpe_resources/qpe_trotter.py:23\u001b[39m, in \u001b[36mcommutator\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcommutator\u001b[39m(a, b):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m - b * a\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/compare/lib/python3.13/site-packages/cirq/ops/linear_combinations.py:820\u001b[39m, in \u001b[36mPauliSum.__mul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m    819\u001b[39m result = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/compare/lib/python3.13/site-packages/cirq/ops/linear_combinations.py:810\u001b[39m, in \u001b[36mPauliSum.__imul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    807\u001b[39m     \u001b[38;5;28mself\u001b[39m._linear_dict = temp._linear_dict\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, PauliSum):\n\u001b[32m    809\u001b[39m     temp = PauliSum.from_pauli_strings(\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m         [\u001b[43mterm\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_term\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m other_term \u001b[38;5;129;01min\u001b[39;00m other]\n\u001b[32m    811\u001b[39m     )\n\u001b[32m    812\u001b[39m     \u001b[38;5;28mself\u001b[39m._linear_dict = temp._linear_dict\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/compare/lib/python3.13/site-packages/cirq/ops/pauli_string.py:276\u001b[39m, in \u001b[36mPauliString.__mul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    274\u001b[39m     known = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m known:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPauliString\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPAULI_STRING_LIKE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mqubit_pauli_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_qubit_pauli_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoefficient\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoefficient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/compare/lib/python3.13/site-packages/cirq/ops/pauli_string.py:196\u001b[39m, in \u001b[36mPauliString.__init__\u001b[39m\u001b[34m(self, qubit_pauli_map, coefficient, *contents)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28mself\u001b[39m._coefficient: cirq.TParamValComplex | sympy.Expr = (\n\u001b[32m    193\u001b[39m     coefficient \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(coefficient, sympy.Expr) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcomplex\u001b[39m(coefficient)\n\u001b[32m    194\u001b[39m )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m contents:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     m = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmutable_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minplace_left_multiply_by\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrozen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28mself\u001b[39m._qubit_pauli_map = m._qubit_pauli_map\n\u001b[32m    198\u001b[39m     \u001b[38;5;28mself\u001b[39m._coefficient = m._coefficient\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/compare/lib/python3.13/site-packages/cirq/ops/pauli_string.py:1315\u001b[39m, in \u001b[36mMutablePauliString.frozen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrozen\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> cirq.PauliString:\n\u001b[32m   1310\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns a `cirq.PauliString` with the same contents.\u001b[39;00m\n\u001b[32m   1311\u001b[39m \n\u001b[32m   1312\u001b[39m \u001b[33;03m    For example, this is useful because `cirq.PauliString` is an operation\u001b[39;00m\n\u001b[32m   1313\u001b[39m \u001b[33;03m    whereas `cirq.MutablePauliString` is not.\u001b[39;00m\n\u001b[32m   1314\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPauliString\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoefficient\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoefficient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mqubit_pauli_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43mq\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_INT_TO_PAULI\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpauli_int_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start_time = perf_counter_ns()\n",
    "group_psums = [sum(group) for group in groups]\n",
    "v2_psum = v2_pauli_sum(group_psums)\n",
    "qubit_map = {q: i for i, q in enumerate(qs)}\n",
    "eps2_psum = v2_psum.expectation_from_state_vector(ground_state_vec, qubit_map)\n",
    "end_time = perf_counter_ns()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Got eps2={eps2_psum} in {elapsed_time:4.5e} ns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776774f",
   "metadata": {},
   "source": [
    "## `of.QubitOperator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = perf_counter_ns()\n",
    "group_qubops = to_groups_of(groups)\n",
    "v2_op = v2_qubop(group_psums)\n",
    "qubit_map = {q: i for i, q in enumerate(qs)}\n",
    "eps2_qubop = v2_psum.expectation_from_state_vector(ground_state_vec, qubit_map)\n",
    "end_time = perf_counter_ns()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Got eps2={eps2_qubop} in {elapsed_time:4.5e} ns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pd39d274q4",
   "metadata": {},
   "source": [
    "## quantum-toolbox (symplectic representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1y2goqjp5k6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Hamiltonian: 630 terms, 12 qubits\n",
      "Grouped into 42 groups in 0.009 s (native symplectic format)\n"
     ]
    }
   ],
   "source": [
    "# Use quantum-toolbox for native symplectic representation\n",
    "import sys\n",
    "sys.path.insert(0, '../quantum-toolbox')\n",
    "from qtoolbox.core.pauli import PauliString\n",
    "from qtoolbox.core.hamiltonian import Hamiltonian\n",
    "from qtoolbox.converters.openfermion_bridge import from_openfermion\n",
    "from qtoolbox.grouping import sorted_insertion_grouping\n",
    "from itertools import accumulate\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Convert OpenFermion QubitOperator to quantum-toolbox Hamiltonian\n",
    "n_qubits_qt = of.utils.count_qubits(hamiltonian_qubop)\n",
    "terms = [from_openfermion(term, coeff, n_qubits_qt)\n",
    "         for term, coeff in hamiltonian_qubop.terms.items() if term]  # skip identity\n",
    "ham = Hamiltonian(terms)\n",
    "print(f\"Loaded Hamiltonian: {ham.num_terms()} terms, {ham.num_qubits()} qubits\")\n",
    "\n",
    "# Group using quantum-toolbox's SI\n",
    "start_group = perf_counter_ns()\n",
    "group_collection = sorted_insertion_grouping(ham)\n",
    "time_grouping = perf_counter_ns() - start_group\n",
    "\n",
    "sym_groups = [list(g.paulis) for g in group_collection.groups]\n",
    "print(f\"Grouped into {len(sym_groups)} groups in {time_grouping/1e9:.3f} s (native symplectic format)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8r2bcphgnio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_commutator_sum(a_terms, b_terms):\n",
    "    result = []\n",
    "    for ai in a_terms:\n",
    "        for bj in b_terms:\n",
    "            if not ai.commutes_with(bj):  \n",
    "                p = ai.multiply(bj)       \n",
    "                p.coeff *= 2              \n",
    "                result.append(p)\n",
    "    return result\n",
    "\n",
    "def apply_pauli_to_state(x_bits, z_bits, n_qubits, state):\n",
    "    dim = len(state)\n",
    "    result = state.copy()\n",
    "\n",
    "    x_bits_of, z_bits_of = 0, 0\n",
    "    for q in range(n_qubits):\n",
    "        if x_bits & (1 << q):\n",
    "            x_bits_of |= (1 << (n_qubits - 1 - q))\n",
    "        if z_bits & (1 << q):\n",
    "            z_bits_of |= (1 << (n_qubits - 1 - q))\n",
    "\n",
    "    if z_bits_of:\n",
    "        indices = np.arange(dim)\n",
    "        parity = np.zeros(dim, dtype=np.int8)\n",
    "        for b in range(n_qubits):\n",
    "            if z_bits_of & (1 << b):\n",
    "                parity ^= ((indices >> b) & 1).astype(np.int8)\n",
    "        result *= (1 - 2*parity)\n",
    "\n",
    "    if x_bits_of:\n",
    "        result = result[np.arange(dim) ^ x_bits_of]\n",
    "\n",
    "    y_bits = x_bits & z_bits\n",
    "    if y_bits:\n",
    "        result *= (1j) ** bin(y_bits).count('1')\n",
    "\n",
    "    return result\n",
    "\n",
    "def build_v2_terms(sym_groups):\n",
    "    nterms = len(sym_groups)\n",
    "    sums_l2r = list(accumulate(sym_groups, lambda a, b: a + b))\n",
    "    sums_r2l = list(reversed(list(accumulate(reversed(sym_groups), lambda a, b: a + b))))\n",
    "    sums_r2l.append([])\n",
    "\n",
    "    v2_terms = []\n",
    "    for i in range(1, nterms):\n",
    "        V1 = fast_commutator_sum(sums_l2r[i-1], sym_groups[i])\n",
    "        for t in fast_commutator_sum(V1, sums_r2l[i+1]):\n",
    "            t.coeff *= -1/3\n",
    "            v2_terms.append(t)\n",
    "        for t in fast_commutator_sum(V1, sym_groups[i]):\n",
    "            t.coeff *= -1/6\n",
    "            v2_terms.append(t)\n",
    "    return v2_terms\n",
    "\n",
    "def compute_expectation_sequential(v2_terms, psi, n_qubits):\n",
    "    eps2 = 0.0\n",
    "    for t in v2_terms:\n",
    "        p_state = apply_pauli_to_state(t.x_bits, t.z_bits, n_qubits, psi)\n",
    "        eps2 += (t.coeff * np.vdot(psi, p_state)).real\n",
    "    return eps2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3u7tuefmzqs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantum-toolbox (sequential):\n",
      "   V2 terms:     7,515,092\n",
      "   eps2 =        0.0097718029\n",
      "   Build time:   20.215 s\n",
      "   Exp. time:    282.903 s\n",
      "   Total time:   303.119 s\n",
      "   Error vs sparse: 1.77e-16\n",
      "   ✓ Validation passed\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter_ns()\n",
    "v2_terms = build_v2_terms(sym_groups)\n",
    "time_build = perf_counter_ns() - start_time\n",
    "\n",
    "start_exp = perf_counter_ns()\n",
    "eps2_symplectic = compute_expectation_sequential(v2_terms, ground_state_vec, nq)\n",
    "time_exp = perf_counter_ns() - start_exp\n",
    "\n",
    "end_time = perf_counter_ns()\n",
    "elapsed_ns = end_time - start_time\n",
    "\n",
    "error = abs(eps2 - eps2_symplectic)\n",
    "print(f\"quantum-toolbox (sequential):\")\n",
    "print(f\"   V2 terms:     {len(v2_terms):,}\")\n",
    "print(f\"   eps2 =        {eps2_symplectic:.10f}\")\n",
    "print(f\"   Build time:   {time_build/1e9:.3f} s\")\n",
    "print(f\"   Exp. time:    {time_exp/1e9:.3f} s\")\n",
    "print(f\"   Total time:   {elapsed_ns/1e9:.3f} s\")\n",
    "print(f\"   Error vs sparse: {error:.2e}\")\n",
    "assert error < 1e-8, f\"Results don't match! Error: {error}\"\n",
    "print(\"   ✓ Validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nfsbmp4w2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expectation_batch(args):\n",
    "    terms_data, psi, n_qubits = args\n",
    "    dim = len(psi)\n",
    "    total = 0.0\n",
    "    for x_bits, z_bits, coeff in terms_data:\n",
    "        result = psi.copy()\n",
    "        x_bits_of, z_bits_of = 0, 0\n",
    "        for q in range(n_qubits):\n",
    "            if x_bits & (1 << q):\n",
    "                x_bits_of |= (1 << (n_qubits - 1 - q))\n",
    "            if z_bits & (1 << q):\n",
    "                z_bits_of |= (1 << (n_qubits - 1 - q))\n",
    "        if z_bits_of:\n",
    "            indices = np.arange(dim)\n",
    "            parity = np.zeros(dim, dtype=np.int8)\n",
    "            for b in range(n_qubits):\n",
    "                if z_bits_of & (1 << b):\n",
    "                    parity ^= ((indices >> b) & 1).astype(np.int8)\n",
    "            result = result * (1 - 2*parity)\n",
    "        if x_bits_of:\n",
    "            result = result[np.arange(dim) ^ x_bits_of]\n",
    "        y_bits = x_bits & z_bits\n",
    "        if y_bits:\n",
    "            result = result * ((1j) ** bin(y_bits).count('1'))\n",
    "        total += (coeff * np.vdot(psi, result)).real\n",
    "    return total\n",
    "\n",
    "def compute_expectation_parallel(v2_terms, psi, n_qubits, n_workers=None):\n",
    "    if n_workers is None:\n",
    "        n_workers = max(1, cpu_count())  \n",
    "    terms_data = [(t.x_bits, t.z_bits, t.coeff) for t in v2_terms]\n",
    "    \n",
    "    batch_size = len(terms_data) // n_workers + 1\n",
    "    batches = [(terms_data[i:i+batch_size], psi, n_qubits) \n",
    "               for i in range(0, len(terms_data), batch_size)]\n",
    "    \n",
    "    with Pool(n_workers) as pool:\n",
    "        results = pool.map(compute_expectation_batch, batches)\n",
    "    return sum(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exhxdenarz5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Build time:   20.934 s\n",
      "quantum-toolbox (parallel, 9 workers):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/benjamindalfavero/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_expectation_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-33:\n",
      "Process SpawnPoolWorker-34:\n",
      "Process SpawnPoolWorker-28:\n",
      "Process SpawnPoolWorker-32:\n",
      "Process SpawnPoolWorker-36:\n",
      "Process SpawnPoolWorker-29:\n",
      "Process SpawnPoolWorker-31:\n",
      "Process SpawnPoolWorker-30:\n",
      "Process SpawnPoolWorker-35:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mquantum-toolbox (parallel, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_workers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m workers):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m start_time = perf_counter_ns()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m eps2_parallel = \u001b[43mcompute_expectation_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv2_terms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_state_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m time_parallel = perf_counter_ns() - start_time\n\u001b[32m     12\u001b[39m error_par = \u001b[38;5;28mabs\u001b[39m(eps2 - eps2_parallel)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mcompute_expectation_parallel\u001b[39m\u001b[34m(v2_terms, psi, n_qubits, n_workers)\u001b[39m\n\u001b[32m     34\u001b[39m batches = [(terms_data[i:i+batch_size], psi, n_qubits) \n\u001b[32m     35\u001b[39m            \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(terms_data), batch_size)]\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(n_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     results = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_expectation_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py:367\u001b[39m, in \u001b[36mPool.map\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    in a list that is returned.\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/threading.py:659\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    657\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start_time = perf_counter_ns()\n",
    "v2_terms = build_v2_terms(sym_groups)\n",
    "time_build = perf_counter_ns() - start_time\n",
    "print(f\"   Build time:   {time_build/1e9:.3f} s\")\n",
    "n_workers = 9\n",
    "print(f\"quantum-toolbox (parallel, {n_workers} workers):\")\n",
    "\n",
    "start_time = perf_counter_ns()\n",
    "eps2_parallel = compute_expectation_parallel(v2_terms, ground_state_vec, nq, n_workers)\n",
    "time_parallel = perf_counter_ns() - start_time\n",
    "\n",
    "error_par = abs(eps2 - eps2_parallel)\n",
    "print(f\"   eps2 =        {eps2_parallel:.10f}\")\n",
    "print(f\"   Time:         {time_parallel/1e9:.3f} s\")\n",
    "assert error_par < 1e-8, f\"Results don't match! Error: {error_par}\"\n",
    "print(\"   ✓ Validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a907c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Hamiltonian: 630 terms, 12 qubits\n",
      "eps2 from toolbox = 9.76879e-03\n"
     ]
    }
   ],
   "source": [
    "# Test with module\n",
    "from qpe_trotter import (\n",
    "    v2_pauli_sum,\n",
    "    build_v2_terms,\n",
    "    compute_expectation_parallel,\n",
    "    compute_expectation_sequential,\n",
    "    get_gate_counts\n",
    ")\n",
    "from qtoolbox.converters.openfermion_bridge import from_openfermion\n",
    "from qtoolbox.grouping import sorted_insertion_grouping\n",
    "from qtoolbox.core.hamiltonian import Hamiltonian\n",
    "terms = [from_openfermion(term, coeff, nq)\n",
    "        for term, coeff in hamiltonian_qubop.terms.items() if term]  # skip identity\n",
    "ham_qt = Hamiltonian(terms)\n",
    "print(f\"Loaded Hamiltonian: {ham_qt.num_terms()} terms, {ham_qt.num_qubits()} qubits\")\n",
    "group_collection = sorted_insertion_grouping(ham_qt)\n",
    "sym_groups = [list(g.paulis) for g in group_collection.groups]\n",
    "v2_terms = build_v2_terms(sym_groups)\n",
    "# eps2_toolbox = compute_expectation_parallel(v2_terms, ground_state_vec, nq, n_workers)\n",
    "eps2_toolbox = compute_expectation_sequential(v2_terms, ground_state_vec, nq)\n",
    "print(f\"eps2 from toolbox = {eps2_toolbox:4.5e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e35412e",
   "metadata": {},
   "source": [
    "## MPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00daf35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_groups_mpo(groups: List[List[cirq.PauliString]], qs: List[cirq.Qid], max_bond: int) -> List[MatrixProductOperator]:\n",
    "    \"\"\"Convert groups from SI into a list of MatrixProductOperators.\"\"\"\n",
    "\n",
    "    mpos: List[MatrixProductOperator] = []\n",
    "    for group in groups:\n",
    "        group_psum = sum(group)\n",
    "        group_mpo = pauli_sum_to_mpo(group_psum, qs, max_bond=max_bond)\n",
    "        mpos.append(group_mpo.copy())\n",
    "    return mpos\n",
    "\n",
    "def mpo_add_compress(\n",
    "    mpo_a: MatrixProductOperator, mpo_b: MatrixProductOperator,\n",
    "    compress: bool = False, max_bond: int = 100\n",
    ") -> MatrixProductOperator:\n",
    "    \"\"\"Add two MPOs, optionally compressing them.\"\"\"\n",
    "\n",
    "    mpo_sum = mpo_a + mpo_b\n",
    "    if compress:\n",
    "        mpo_sum.compress(max_bond=max_bond)\n",
    "    return mpo_sum\n",
    "\n",
    "\n",
    "def mpo_commutator(mpo_a: MatrixProductOperator, mpo_b: MatrixProductOperator) -> MatrixProductOperator:\n",
    "    \"\"\"Take the commutator of two MPOs.\"\"\"\n",
    "\n",
    "    return mpo_a.apply(mpo_b) - mpo_b.apply(mpo_a)\n",
    "\n",
    "\n",
    "def zeros_mpo(nsites: int, phys_dim: int=2) -> MatrixProductOperator:\n",
    "    \"\"\"Returns an MPO corresponding to a matirx of all zeros.\"\"\"\n",
    "\n",
    "    def fill_fun(shape):\n",
    "        return np.zeros(shape, dtype=complex)\n",
    "    \n",
    "    return MatrixProductOperator.from_fill_fn(fill_fun, L=nsites, bond_dim=1, phys_dim=phys_dim)\n",
    "\n",
    "\n",
    "def get_v2_contrib_mpo(fragments_list: List[MatrixProductOperator], psi: MatrixProductState, max_bond: int) -> float:\n",
    "    \"\"\"Calculate eps2 when the fragments are MPOs.\"\"\"\n",
    "\n",
    "    max_mpo_sites = max([len(mpo.tensor_map) for mpo in fragments_list])\n",
    "\n",
    "    frags_len = len(fragments_list)\n",
    "    frag_sums_l2r = list(accumulate(fragments_list, lambda a, b: mpo_add_compress(a, b, True, max_bond)))\n",
    "    temp = reversed(fragments_list)\n",
    "    frag_sums_r2l = list(accumulate(temp, lambda a, b: mpo_add_compress(a, b, True, max_bond)))\n",
    "    frag_sums_r2l = list(reversed(frag_sums_r2l))\n",
    "    frag_sums_r2l.append(zeros_mpo(max_mpo_sites))\n",
    "    frag_combs_V1_v2 = [(frag_sums_l2r[i-1], fragments_list[i], frag_sums_r2l[i+1]) for i in range (1, frags_len)]\n",
    "    eps2 = 0\n",
    "    for i,j,k in frag_combs_V1_v2:\n",
    "        V1_term = mpo_commutator(i, j)\n",
    "        term1 = psi.H @ psi.gate_with_mpo(mpo_commutator(V1_term, k))\n",
    "        term2 = psi.H @ psi.gate_with_mpo(mpo_commutator(V1_term, j))\n",
    "        eps2 += - term1 *1/3 - term2 *1/6\n",
    "    return eps2.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mpo_bond = 5\n",
    "start_time = perf_counter_ns()\n",
    "mpo_fragments = to_groups_mpo(groups, qs, max_mpo_bond)\n",
    "end_time = perf_counter_ns()\n",
    "elapsed_time_convert = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be18c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return func(*args, **kwargs)\n",
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: overflow encountered in matmul\n",
      "  return func(*args, **kwargs)\n",
      "/Users/benjamindalfavero/.venv/compare/lib/python3.13/site-packages/autoray/autoray.py:81: RuntimeWarning: invalid value encountered in matmul\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got eps2=0.009230812660028556.\n",
      "Conversion time: 1.23026e+09, calculation time: 8.41664e+10.\n",
      "Error 5.40575e-04\n"
     ]
    }
   ],
   "source": [
    "start_time = perf_counter_ns()\n",
    "eps2_mpo = get_v2_contrib_mpo(mpo_fragments, ground_state, max_mpo_bond)\n",
    "end_time = perf_counter_ns()\n",
    "elapsed_time_calculate = end_time - start_time\n",
    "\n",
    "print(f\"Got eps2={eps2_mpo}.\")\n",
    "print(f\"Conversion time: {elapsed_time_convert:4.5e}, calculation time: {elapsed_time_calculate:4.5e}.\")\n",
    "eps2_err = abs(eps2 - eps2_mpo)\n",
    "print(f\"Error {eps2_err:4.5e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18234c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compare (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
